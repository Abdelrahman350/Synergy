Epoch 1/100:
2021-12-02 15:38:57.765301: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100
2021-12-02 15:38:58.505032: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.




































































































































































































































































































































3266/3266 [==============================] - 654s 200ms/step - train_loss: 1535.7990































555/559 [============================>.] - ETA: 0s - valid_loss: 1258.6527
559/559 [==============================] - 63s 113ms/step - valid_loss: 1258.7258 - train_loss: 1535.7990 - val_loss: 1258.7258





































































































































































































































































































































3266/3266 [==============================] - 653s 200ms/step - train_loss: 967.0188






























542/559 [============================>.] - ETA: 2s - valid_loss: 490.2648

559/559 [==============================] - 63s 113ms/step - valid_loss: 490.1935 - train_loss: 967.0189 - val_loss: 490.1935






































































































































































































































































































































3266/3266 [==============================] - 657s 201ms/step - train_loss: 436.9934































551/559 [============================>.] - ETA: 1s - valid_loss: 156.0367
559/559 [==============================] - 64s 114ms/step - valid_loss: 156.1570 - train_loss: 436.9934 - val_loss: 156.1570







































































































































































































































































































































3266/3266 [==============================] - 658s 201ms/step - train_loss: 94.1813































559/559 [==============================] - 64s 114ms/step - valid_loss: 62.8812 - train_loss: 94.1814 - val_loss: 62.8812
   4/3266 [..............................] - ETA: 10:52 - train_loss: 61.4324












































































































































































































































































































































3266/3266 [==============================] - 668s 205ms/step - train_loss: 60.7394































547/559 [============================>.] - ETA: 1s - valid_loss: 58.7555
559/559 [==============================] - 64s 114ms/step - valid_loss: 58.7769 - train_loss: 60.7394 - val_loss: 58.7769











































































































































































































































































































































3266/3266 [==============================] - 665s 203ms/step - train_loss: 58.9410































552/559 [============================>.] - ETA: 0s - valid_loss: 58.0158
559/559 [==============================] - 64s 114ms/step - valid_loss: 58.0077 - train_loss: 58.9410 - val_loss: 58.0077








































































































1033/3266 [========>.....................] - ETA: 7:32 - train_loss: 58.0840
Traceback (most recent call last):
  File "train.py", line 47, in <module>
    train(model, training_data_generator, validation_data_generator, 100,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 22, in train
    train_loss = train_batch(X_batch,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 54, in train_batch
    loss_value = loss_function(y_true, y_pred)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py", line 1084, in gradient
    flat_grad = imperative_grad.imperative_grad(
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py", line 71, in imperative_grad
    return pywrap_tfe.TFE_Py_TapeGradient(
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py", line 159, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py", line 1622, in _SquaredDifferenceGrad
    x_grad = math_ops.scalar_mul(2.0, grad) * (x - y)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 1096, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 622, in scalar_mul
    scalar = ops.convert_to_tensor(
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)

1041/3266 [========>.....................] - ETA: 7:30 - train_loss: 58.1151
Epoch 1/100:
2021-12-02 19:18:02.216834: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100
2021-12-02 19:18:02.960884: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.























































































































































































































































































1633/1633 [==============================] - 571s 349ms/step - train_loss: 1941.7136





























275/279 [============================>.] - ETA: 1s - valid_loss: 1862.5178
279/279 [==============================] - 60s 215ms/step - valid_loss: 1862.9626 - train_loss: 1941.7137 - val_loss: 1862.9626
The validation loss improved from inf to 1862.962646484375.                 Saving model Model.h5






























































































































































































































































































1633/1633 [==============================] - 575s 352ms/step - train_loss: 1870.7759





























279/279 [==============================] - 60s 214ms/step - valid_loss: 1862.6224 - train_loss: 1870.7759 - val_loss: 1862.6224
The validation loss improved from 1862.962646484375 to 1862.6224365234375.                 Saving model Model.h5
Epoch 3/100:
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 1870.7448





























273/279 [============================>.] - ETA: 1s - valid_loss: 1862.4344
279/279 [==============================] - 61s 216ms/step - valid_loss: 1862.6332 - train_loss: 1870.7448 - val_loss: 1862.6332

































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 1870.7025





























276/279 [============================>.] - ETA: 0s - valid_loss: 1862.6375
279/279 [==============================] - 61s 216ms/step - valid_loss: 1862.9558 - train_loss: 1870.7025 - val_loss: 1862.9558












































































































 609/1633 [==========>...................] - ETA: 6:05 - train_loss: 1873.1051
Traceback (most recent call last):
  File "train.py", line 40, in <module>
    train(model, training_data_generator, validation_data_generator, 100,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 26, in train
    pb_1.update(batch, values)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/keras/utils/generic_utils.py", line 958, in update
    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))
  File "<__array_function__ internals>", line 5, in mean
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 3440, in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/numpy/core/_methods.py", line 163, in _mean
    arr = asanyarray(a)

 610/1633 [==========>...................] - ETA: 6:05 - train_loss: 1873.1051
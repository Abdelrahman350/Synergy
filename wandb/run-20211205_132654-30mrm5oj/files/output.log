Epoch 1/500:
2021-12-05 13:26:58.038200: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100
2021-12-05 13:26:59.114668: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.












































































































































































 278/1633 [====>.........................] - ETA: 27:59 - train_loss: 1961.0974
Traceback (most recent call last):
  File "train.py", line 40, in <module>
    train(model, training_data_generator, validation_data_generator, 500,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 32, in train
    train_loss = train_batch(X_batch,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 69, in train_batch
    optimizer.apply_gradients(zip(grads, model.trainable_weights))
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py", line 672, in apply_gradients
    return self._distributed_apply(strategy, grads_and_vars, name,
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py", line 721, in _distributed_apply
    update_op = distribution.extended.update(
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2634, in update
    return self._update(var, fn, args, kwargs, group)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3709, in _update
    return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 3715, in _update_non_slot
    result = fn(*args, **kwargs)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py", line 601, in wrapper
    return func(*args, **kwargs)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py", line 704, in apply_grad_to_update_var
    update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/keras/optimizer_v2/nadam.py", line 161, in _resource_apply_dense
    tf.sqrt(v_t_prime) + coefficients['epsilon'])
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py", line 1096, in op_dispatch_handler
    return dispatch_target(*args, **kwargs)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py", line 5378, in sqrt
    return gen_math_ops.sqrt(x, name)
KeyboardInterrupt
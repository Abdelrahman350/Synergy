
2021-12-04 20:55:19.903965: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100
2021-12-04 20:55:20.650774: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
   0/1633 [..............................] - ETA: 0s - train_loss: 40.7835
Loaded model with validation_loss = 41.92481994628906
































































































































































































































































































































































1633/1633 [==============================] - 707s 432ms/step - train_loss: 41.6084





























273/279 [============================>.] - ETA: 1s - valid_loss: 42.3484
279/279 [==============================] - 60s 213ms/step - valid_loss: 42.3360 - train_loss: 41.6084 - val_loss: 42.3360





































































































































































































































































































































































1633/1633 [==============================] - 717s 439ms/step - train_loss: 41.4109





























276/279 [============================>.] - ETA: 0s - valid_loss: 42.1500
279/279 [==============================] - 60s 214ms/step - valid_loss: 42.1509 - train_loss: 41.4109 - val_loss: 42.1509



















































































































































































 815/1633 [=============>................] - ETA: 6:01 - train_loss: 42.8225
Traceback (most recent call last):
  File "train.py", line 40, in <module>
    train(model, training_data_generator, validation_data_generator, 100,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 32, in train
    train_loss = train_batch(X_batch,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 68, in train_batch
    grads = tape.gradient(loss_value, model.trainable_weights)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py", line 1084, in gradient
    flat_grad = imperative_grad.imperative_grad(
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py", line 71, in imperative_grad
    return pywrap_tfe.TFE_Py_TapeGradient(
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py", line 159, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/nn_grad.py", line 591, in _Conv2DGrad
    gen_nn_ops.conv2d_backprop_filter(
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 1080, in conv2d_backprop_filter
    _result = pywrap_tfe.TFE_Py_FastPathExecute(

 817/1633 [==============>...............] - ETA: 6:00 - train_loss: 42.8191
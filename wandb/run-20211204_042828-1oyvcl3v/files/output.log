
2021-12-04 04:28:30.956900: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100
2021-12-04 04:28:31.702810: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
   0/1633 [..............................] - ETA: 0s - train_loss: 82.2388



















































































































































































































































































1633/1633 [==============================] - 565s 345ms/step - train_loss: 103.8036



























279/279 [==============================] - 58s 206ms/step - valid_loss: 103.2195 - train_loss: 103.8036 - val_loss: 103.2195
   0/1633 [..............................] - ETA: 0s - train_loss: 86.5965
























































































































































































































































































1633/1633 [==============================] - 563s 345ms/step - train_loss: 105.1755




























279/279 [==============================] - 58s 206ms/step - valid_loss: 134.9846 - train_loss: 105.1755 - val_loss: 134.9846
   2/1633 [..............................] - ETA: 9:17 - train_loss: 124.9684
























































































































































































































































































1633/1633 [==============================] - 563s 344ms/step - train_loss: 105.4320




























279/279 [==============================] - 58s 206ms/step - valid_loss: 98.3690 - train_loss: 105.4320 - val_loss: 98.3690
   3/1633 [..............................] - ETA: 9:25 - train_loss: 96.3261
























































































































































































































































































1633/1633 [==============================] - 564s 345ms/step - train_loss: 92.0981




























279/279 [==============================] - 58s 205ms/step - valid_loss: 90.5454 - train_loss: 92.0980 - val_loss: 90.5454
The validation loss improved from 96.6547622680664 to 90.5453872680664.                 Saving model Model.h5
   0/1633 [..............................] - ETA: 0s - train_loss: 76.8442































































































































































































































































































1633/1633 [==============================] - 576s 353ms/step - train_loss: 108.9944





























279/279 [==============================] - 60s 214ms/step - valid_loss: 111.3662 - train_loss: 108.9944 - val_loss: 111.3662
   3/1633 [..............................] - ETA: 9:35 - train_loss: 104.6193































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 97.1369





























273/279 [============================>.] - ETA: 1s - valid_loss: 76.6431
279/279 [==============================] - 60s 214ms/step - valid_loss: 76.6460 - train_loss: 97.1369 - val_loss: 76.6460
The validation loss improved from 90.5453872680664 to 76.64603424072266.                 Saving model Model.h5
































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 86.3123




























269/279 [===========================>..] - ETA: 2s - valid_loss: 87.1538

279/279 [==============================] - 60s 214ms/step - valid_loss: 87.0576 - train_loss: 86.3123 - val_loss: 87.0576































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 80.4113





























274/279 [============================>.] - ETA: 1s - valid_loss: 74.5016
279/279 [==============================] - 60s 214ms/step - valid_loss: 74.5262 - train_loss: 80.4113 - val_loss: 74.5262
The validation loss improved from 76.64603424072266 to 74.52617645263672.                 Saving model Model.h5































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 75.1730





























272/279 [============================>.] - ETA: 1s - valid_loss: 76.2245

279/279 [==============================] - 60s 214ms/step - valid_loss: 76.2194 - train_loss: 75.1730 - val_loss: 76.2194































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 72.2826





























275/279 [============================>.] - ETA: 1s - valid_loss: 66.6755
279/279 [==============================] - 60s 214ms/step - valid_loss: 66.6840 - train_loss: 72.2826 - val_loss: 66.6840
The validation loss improved from 74.52617645263672 to 66.68400573730469.                 Saving model Model.h5































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 67.1198





























279/279 [==============================] - 60s 214ms/step - valid_loss: 74.8848 - train_loss: 67.1198 - val_loss: 74.8848
   3/1633 [..............................] - ETA: 9:34 - train_loss: 71.1478
































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 70.5864





























279/279 [==============================] - 60s 214ms/step - valid_loss: 80.3009 - train_loss: 70.5864 - val_loss: 80.3009
Epoch 13/100:































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 68.8349





























271/279 [============================>.] - ETA: 1s - valid_loss: 68.3346
279/279 [==============================] - 60s 214ms/step - valid_loss: 68.2559 - train_loss: 68.8349 - val_loss: 68.2559
































































































































































































































































































1633/1633 [==============================] - 579s 354ms/step - train_loss: 74.4482





























275/279 [============================>.] - ETA: 1s - valid_loss: 82.5371
279/279 [==============================] - 60s 214ms/step - valid_loss: 82.5291 - train_loss: 74.4482 - val_loss: 82.5291
































































































































































































































































































1633/1633 [==============================] - 578s 354ms/step - train_loss: 70.0785





























277/279 [============================>.] - ETA: 0s - valid_loss: 66.0068
279/279 [==============================] - 60s 214ms/step - valid_loss: 66.0113 - train_loss: 70.0785 - val_loss: 66.0113
The validation loss improved from 66.68400573730469 to 66.01129913330078.                 Saving model Model.h5
































































































































































































































































































1633/1633 [==============================] - 579s 354ms/step - train_loss: 75.4786




























279/279 [==============================] - 60s 214ms/step - valid_loss: 78.4872 - train_loss: 75.4786 - val_loss: 78.4872
   0/1633 [..............................] - ETA: 0s - train_loss: 72.2662
































































































































































































































































































1633/1633 [==============================] - 579s 354ms/step - train_loss: 89.0085





























273/279 [============================>.] - ETA: 1s - valid_loss: 78.4632
279/279 [==============================] - 60s 214ms/step - valid_loss: 78.4667 - train_loss: 89.0085 - val_loss: 78.4667

































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 69.0817





























277/279 [============================>.] - ETA: 0s - valid_loss: 62.0394
279/279 [==============================] - 60s 215ms/step - valid_loss: 62.0404 - train_loss: 69.0817 - val_loss: 62.0404
The validation loss improved from 66.01129913330078 to 62.04037857055664.                 Saving model Model.h5
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 68.8889





























270/279 [===========================>..] - ETA: 2s - valid_loss: 57.6544
279/279 [==============================] - 60s 215ms/step - valid_loss: 57.6159 - train_loss: 68.8889 - val_loss: 57.6159
The validation loss improved from 62.04037857055664 to 57.61585235595703.                 Saving model Model.h5
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 62.6917





























274/279 [============================>.] - ETA: 1s - valid_loss: 90.2981
279/279 [==============================] - 60s 214ms/step - valid_loss: 90.2927 - train_loss: 62.6917 - val_loss: 90.2927

































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 70.8893





























276/279 [============================>.] - ETA: 0s - valid_loss: 63.6895
279/279 [==============================] - 60s 215ms/step - valid_loss: 63.7265 - train_loss: 70.8893 - val_loss: 63.7265
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 80.5823





























279/279 [==============================] - 60s 215ms/step - valid_loss: 92.6575 - train_loss: 80.5823 - val_loss: 92.6575
   4/1633 [..............................] - ETA: 9:39 - train_loss: 91.3835
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 69.1421






























279/279 [==============================] - 60s 215ms/step - valid_loss: 92.3098 - train_loss: 69.1421 - val_loss: 92.3098
Epoch 24/100:
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 81.3355





























273/279 [============================>.] - ETA: 1s - valid_loss: 84.0265
279/279 [==============================] - 60s 215ms/step - valid_loss: 84.0365 - train_loss: 81.3355 - val_loss: 84.0365

































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 71.4074





























276/279 [============================>.] - ETA: 0s - valid_loss: 68.9278
279/279 [==============================] - 60s 215ms/step - valid_loss: 68.9401 - train_loss: 71.4074 - val_loss: 68.9401
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 81.9493





























272/279 [============================>.] - ETA: 1s - valid_loss: 59.5874
279/279 [==============================] - 60s 214ms/step - valid_loss: 59.5783 - train_loss: 81.9493 - val_loss: 59.5783
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 73.5498





























279/279 [==============================] - 60s 215ms/step - valid_loss: 80.5121 - train_loss: 73.5498 - val_loss: 80.5121
   0/1633 [..............................] - ETA: 0s - train_loss: 80.1029

































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 93.2058





























274/279 [============================>.] - ETA: 1s - valid_loss: 70.3352
279/279 [==============================] - 60s 215ms/step - valid_loss: 70.3583 - train_loss: 93.2058 - val_loss: 70.3583
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 111.8645





























279/279 [==============================] - 60s 215ms/step - valid_loss: 101.6228 - train_loss: 111.8645 - val_loss: 101.6228
   0/1633 [..............................] - ETA: 0s - train_loss: 86.7963

































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 77.8134





























275/279 [============================>.] - ETA: 1s - valid_loss: 71.9530
279/279 [==============================] - 60s 215ms/step - valid_loss: 71.9325 - train_loss: 77.8134 - val_loss: 71.9325
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 120.2924





























274/279 [============================>.] - ETA: 1s - valid_loss: 188.7754
279/279 [==============================] - 60s 215ms/step - valid_loss: 188.7823 - train_loss: 120.2924 - val_loss: 188.7823
































































































































































































































































































1633/1633 [==============================] - 580s 355ms/step - train_loss: 98.6651





























279/279 [==============================] - 60s 214ms/step - valid_loss: 85.4731 - train_loss: 98.6651 - val_loss: 85.4731
   0/1633 [..............................] - ETA: 0s - train_loss: 87.4618

























































































































































































































































































1633/1633 [==============================] - 565s 346ms/step - train_loss: 77.6718




























279/279 [==============================] - 58s 206ms/step - valid_loss: 64.0018 - train_loss: 77.6718 - val_loss: 64.0018
   3/1633 [..............................] - ETA: 9:24 - train_loss: 67.4196

























































































































































































































































































1633/1633 [==============================] - 565s 346ms/step - train_loss: 182.3495




























276/279 [============================>.] - ETA: 0s - valid_loss: 194.0583
279/279 [==============================] - 58s 205ms/step - valid_loss: 193.9853 - train_loss: 182.3495 - val_loss: 193.9853

























































































































































































































































































1633/1633 [==============================] - 565s 346ms/step - train_loss: 147.1028




























276/279 [============================>.] - ETA: 0s - valid_loss: 107.2472
279/279 [==============================] - 58s 206ms/step - valid_loss: 107.1236 - train_loss: 147.1028 - val_loss: 107.1236
























































































































































































































































































1633/1633 [==============================] - 564s 345ms/step - train_loss: 138.2082




























273/279 [============================>.] - ETA: 1s - valid_loss: 194.7531
279/279 [==============================] - 58s 206ms/step - valid_loss: 194.8366 - train_loss: 138.2082 - val_loss: 194.8366

























































































































































































































































































1633/1633 [==============================] - 566s 346ms/step - train_loss: 127.3604




























272/279 [============================>.] - ETA: 1s - valid_loss: 214.4986
279/279 [==============================] - 58s 206ms/step - valid_loss: 214.4174 - train_loss: 127.3604 - val_loss: 214.4174

























































































































































































































































































1633/1633 [==============================] - 564s 345ms/step - train_loss: 140.7510




























277/279 [============================>.] - ETA: 0s - valid_loss: 97.9613
279/279 [==============================] - 58s 206ms/step - valid_loss: 97.9427 - train_loss: 140.7510 - val_loss: 97.9427

























































































































































































































































































1633/1633 [==============================] - 566s 346ms/step - train_loss: 100.3668




























273/279 [============================>.] - ETA: 1s - valid_loss: 85.4239
279/279 [==============================] - 58s 206ms/step - valid_loss: 85.4841 - train_loss: 100.3668 - val_loss: 85.4841
























































































































































































































































































1633/1633 [==============================] - 564s 345ms/step - train_loss: 93.5461




























270/279 [===========================>..] - ETA: 2s - valid_loss: 83.3978
279/279 [==============================] - 58s 205ms/step - valid_loss: 83.4412 - train_loss: 93.5461 - val_loss: 83.4412

























































































































































































































































































1633/1633 [==============================] - 565s 346ms/step - train_loss: 112.1755




























279/279 [==============================] - 58s 206ms/step - valid_loss: 75.8685 - train_loss: 112.1755 - val_loss: 75.8685
   1/1633 [..............................] - ETA: 16:46 - train_loss: 77.0747








  46/1633 [..............................] - ETA: 9:09 - train_loss: 75.7840
Traceback (most recent call last):
  File "train.py", line 40, in <module>
    train(model, training_data_generator, validation_data_generator, 100,\
  File "/media/avidbeam/workspace/Abdelrahman_Workspace/Project_Codes/Synergy/utils/custom_fit.py", line 35, in train
    pb_1.update(batch, values)
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/keras/utils/generic_utils.py", line 958, in update
    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))
  File "<__array_function__ internals>", line 5, in mean
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 3440, in mean
    return _methods._mean(a, axis=axis, dtype=dtype,
  File "/home/avidbeam/.virtualenvs/TensorFlow_2/lib/python3.8/site-packages/numpy/core/_methods.py", line 163, in _mean
    arr = asanyarray(a)
KeyboardInterrupt